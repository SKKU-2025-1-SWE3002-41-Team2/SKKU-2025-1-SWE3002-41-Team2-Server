from typing import List, Optional, Dict, Any
import os
from datetime import datetime
from openai import OpenAI
from pydantic import BaseModel, Field

from app.schemas.excel_schemas import LLMExcelResponse, ExcelCommand
from app.services.excel_service import ExcelService
from app.services.excel_commands import CommandType


# Structured Outputì„ ìœ„í•œ Pydantic ëª¨ë¸
# ì´ ëª¨ë¸ì€ OpenAIì˜ Structured Output ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬
# ëª…ë ¹ì–´ ì‹œí€€ìŠ¤ë¥¼ ì •ì˜í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
class ExcelCommandOutput(BaseModel):
    command_type: str = Field(description="ëª…ë ¹ì–´ íƒ€ì…")
    target_range: str = Field(description="ëŒ€ìƒ ì…€ ë²”ìœ„ (ì˜ˆ: A1:B10)")
    parameters: Dict[str, Any] = Field(description="ëª…ë ¹ì–´ íŒŒë¼ë¯¸í„°")


class LLMResponseOutput(BaseModel):
    """LLM ì‘ë‹µ ì¶œë ¥ êµ¬ì¡°"""
    response: str = Field(description="ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ í•œêµ­ì–´ ì‘ë‹µ")
    commands: List[ExcelCommandOutput] = Field(description="ì‹¤í–‰í•  ì—‘ì…€ ëª…ë ¹ì–´ ì‹œí€€ìŠ¤")
    summary: str = Field(description="ì´ë²ˆ ì‘ë‹µì˜ ë‚´ìš©ì„ ë°˜ì˜í•œ ê°±ì‹ ëœ ìš”ì•½")


def get_openai_friendly_schema():
    return {
        "name": "LLMResponseOutput",  # âœ… ì´ë¦„
        "schema": {                   # âœ… ì‹¤ì œ ìŠ¤í‚¤ë§ˆ ë‚´ìš©
            "type": "object",
            "title": "LLMResponseOutput",
            "properties": {
                "response": {
                    "type": "string",
                    "description": "ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ í•œêµ­ì–´ ì‘ë‹µ"
                },
                "commands": {
                    "type": "array",
                    "description": "ì‹¤í–‰í•  ì—‘ì…€ ëª…ë ¹ì–´ ì‹œí€€ìŠ¤",
                    "items": {
                        "type": "object",
                        "properties": {
                            "command_type": {"type": "string", "description": "ëª…ë ¹ì–´ íƒ€ì…"},
                            "target_range": {"type": "string", "description": "ëŒ€ìƒ ì…€ ë²”ìœ„ (ì˜ˆ: A1:B10)"},
                            "parameters": {"type": "object", "description": "ëª…ë ¹ì–´ íŒŒë¼ë¯¸í„°"}
                        },
                        "required": ["command_type", "target_range", "parameters"]
                    }
                },
                "summary": {
                    "type": "string",
                    "description": "ì´ë²ˆ ì‘ë‹µì˜ ë‚´ìš©ì„ ë°˜ì˜í•œ ê°±ì‹ ëœ ìš”ì•½"
                }
            },
            "required": ["response", "commands", "summary"]
        }
    }


class LLMExcelService:
    """LLMê³¼ ì—‘ì…€ í†µí•© ì„œë¹„ìŠ¤"""

    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.client = OpenAI(api_key=api_key)
        self.excel_service = ExcelService()



    def process_excel_command(
            self,
            user_command: str,
            summary: str,
            excel_bytes: bytes
    ) -> LLMExcelResponse:
        """
        ì‚¬ìš©ì ëª…ë ¹ì„ ì²˜ë¦¬í•˜ì—¬ ì—‘ì…€ ëª…ë ¹ì–´ ì‹œí€€ìŠ¤ ìƒì„±

        ì‘ë™ ê³¼ì •:
        1. í˜„ì¬ ì—‘ì…€ íŒŒì¼ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        2. GPTì—ê²Œ ì—­í• ê³¼ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ë¥¼ ì„¤ëª…í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        3. ì‚¬ìš©ìì˜ ëª…ë ¹ê³¼ í˜„ì¬ ìƒí™©ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        4. GPT-4ì— structured output í˜•ì‹ìœ¼ë¡œ ìš”ì²­
        5. ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ExcelCommand ê°ì²´ë¡œ ë³€í™˜
        6. ì±„íŒ… ìš”ì•½ ì—…ë°ì´íŠ¸
        """

        # 1. ì—‘ì…€ íŒŒì¼ì˜ í˜„ì¬ ìƒíƒœë¥¼ ë¶„ì„
        excel_context = self._analyze_excel_context(excel_bytes)

        # 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = self._create_system_prompt()

        # 3. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        user_prompt = self._create_user_prompt(
            summary,
            user_command,
            excel_context
        )
        print("in 1")
        # 4. OpenAI Structured Output ì‚¬ìš©
        completion = self.client.beta.chat.completions.parse(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_schema", "json_schema": get_openai_friendly_schema()},
            max_tokens=1 << 15,
            temperature=0.7 # (ì˜¨ë„ ì¡°ì ˆ: 0.7ì€ ì ë‹¹í•œ ì°½ì˜ì„±)
        )
        print("in 2")
        print("âœ… í”„ë¡¬í”„íŠ¸ í† í°:", completion.usage.prompt_tokens)
        print("âœ… ì‘ë‹µ í† í°:", completion.usage.completion_tokens)
        print("âœ… ì´ í† í°:", completion.usage.total_tokens)

        # 5. ì‘ë‹µ íŒŒì‹±
        parsed_response = completion.choices[0].message.parsed
        print("ğŸ’¬ GPT ì›ë¬¸ ì‘ë‹µ:", completion.choices[0].message.content)
        print("ğŸ” Parsed ê²°ê³¼:", parsed_response)

        # 6. ExcelCommand ê°ì²´ë¡œ ë³€í™˜
        commands = []
        for cmd in parsed_response.commands:
            commands.append(ExcelCommand(
                command_type=cmd.command_type,
                target_range=cmd.target_range,
                parameters=cmd.parameters
            ))

        # 7. ì±„íŒ… ìš”ì•½ ì—…ë°ì´íŠ¸


        # 8. ì—‘ì…€ ëª…ë ¹ì–´ ì‹¤í–‰
        # ì¸ìˆ˜ì¸ê³„ íŒŒì¼ì—ì„œ ì´ì „ì— ì„¤ëª…í•œ excel_service.execute_command ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬
        # ê° ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        return LLMExcelResponse(
            response=parsed_response.response,
            updated_summary=parsed_response.summary or "",
            excel_func_sequence=commands
        )

    def _analyze_excel_context(self, excel_bytes: bytes) -> str:
        """
        ì—‘ì…€ íŒŒì¼ì˜ í˜„ì¬ ìƒíƒœë¥¼ ë¶„ì„í•˜ì—¬ GPTê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        ë¶„ì„ ë‚´ìš©:
        - ì‹œíŠ¸ì˜ í¬ê¸° (í–‰/ì—´ ê°œìˆ˜)
        - ë°ì´í„°ê°€ ìˆëŠ” ì…€ì˜ ìœ„ì¹˜ì™€ ë‚´ìš© ìƒ˜í”Œ
        - í˜„ì¬ ì ìš©ëœ ìˆ˜ì‹ì´ ìˆë‹¤ë©´ ê·¸ ì •ë³´
        """
        try:
            workbook = self.excel_service.load_excel_from_bytes(excel_bytes)
            ws = workbook.active

            # ë°ì´í„°ê°€ ìˆëŠ” ë²”ìœ„ í™•ì¸
            max_row = ws.max_row
            max_col = ws.max_column

            # ê°„ë‹¨í•œ ìš”ì•½ ìƒì„±
            context = f"í˜„ì¬ ì—‘ì…€ ì‹œíŠ¸: {max_row}í–‰ x {max_col}ì—´\n"

            # ë°ì´í„°ê°€ ìˆëŠ” ì…€ë“¤ì˜ ìƒ˜í”Œ ìˆ˜ì§‘
            sample_data = []
            formula_cells = []

            for row in range(1, min(11, max_row + 1)):  # ìµœëŒ€ 10í–‰ê¹Œì§€
                for col in range(1, min(11, max_col + 1)):  # ìµœëŒ€ 10ì—´ê¹Œì§€
                    cell = ws.cell(row=row, column=col)
                    if cell.value:
                        cell_ref = cell.coordinate

                        # ìˆ˜ì‹ì¸ì§€ í™•ì¸
                        if isinstance(cell.value, str) and cell.value.startswith('='):
                            formula_cells.append(f"{cell_ref}: {cell.value}")
                        else:
                            sample_data.append(f"{cell_ref}: {cell.value}")

            if sample_data:
                context += "\në°ì´í„° ìƒ˜í”Œ:\n" + "\n".join(sample_data[:20])

            if formula_cells:
                context += "\n\nìˆ˜ì‹:\n" + "\n".join(formula_cells)

            return context

        except Exception as e:
            return f"ì—‘ì…€ íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"

    def _create_system_prompt(self) -> str:
        """GPTì˜ ì—­í• ê³¼ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ë¥¼ ì •ì˜í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ì—‘ì…€ íŒŒì¼ í¸ì§‘ì„ ë„ì™€ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹ì„ ì´í•´í•˜ê³ , ì´ë¥¼ êµ¬ì²´ì ì¸ ì—‘ì…€ ëª…ë ¹ì–´ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ íƒ€ì…:
- í•¨ìˆ˜: sum(í•©ê³„), average(í‰ê· ), count(ê°œìˆ˜), max(ìµœëŒ€ê°’), min(ìµœì†Œê°’)
- ì„œì‹: bold(êµµê²Œ), italic(ê¸°ìš¸ì„), underline(ë°‘ì¤„), font_color(ê¸€ììƒ‰), fill_color(ë°°ê²½ìƒ‰), border(í…Œë‘ë¦¬), font_size(ê¸€ìí¬ê¸°), font_name(ê¸€ê¼´)
- ë°ì´í„°: set_value(ê°’ ì„¤ì •), clear(ì§€ìš°ê¸°), merge(ë³‘í•©), unmerge(ë³‘í•© í•´ì œ)
- ì •ë ¬: align_left(ì™¼ìª½ ì •ë ¬), align_center(ê°€ìš´ë° ì •ë ¬), align_right(ì˜¤ë¥¸ìª½ ì •ë ¬), align_top(ìœ„ìª½ ì •ë ¬), align_middle(ì¤‘ê°„ ì •ë ¬), align_bottom(ì•„ë˜ìª½ ì •ë ¬)

ëª…ë ¹ì–´ ì‘ì„± ê·œì¹™:
1. target_rangeëŠ” Excel í˜•ì‹ìœ¼ë¡œ í‘œí˜„ (ì˜ˆ: "A1", "B2:C5")
2. ìƒ‰ìƒì€ 16ì§„ìˆ˜ 6ìë¦¬ë¡œ í‘œí˜„ (ì˜ˆ: "FF0000" = ë¹¨ê°„ìƒ‰, "0000FF" = íŒŒë€ìƒ‰)
3. ëª…ë ¹ì–´ëŠ” ì‹¤í–‰ ìˆœì„œë¥¼ ê³ ë ¤í•˜ì—¬ ë…¼ë¦¬ì ìœ¼ë¡œ ë°°ì¹˜
4. ìˆ˜ì‹ ëª…ë ¹ì˜ ê²½ìš° parametersì— 'range' í‚¤ë¡œ ê³„ì‚° ë²”ìœ„ ì§€ì •
5. summaryëŠ” ì…ë ¥ë°›ì€ summaryì™€ ì´ë²ˆ ì‘ë‹µì—ì„œì˜ ì—‘ì…€ ì‹œí€€ìŠ¤ë¥¼ í†µí•œ ë³€ê²½ì ì„ ë°˜ì˜í•´ ê°±ì‹ í•´ì„œ ì‘ë‹µ
6. summaryëŠ” ê°±ì‹ í•´ì„œ 1000ì ì´í•˜ë¡œ ì‘ë‹µ
7. ëª¨ë“  ëª…ë ¹ì–´ëŠ” `parameters` í•„ë“œë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
- íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•œ ëª…ë ¹ì–´ëŠ” ì‹¤ì œ í‚¤-ê°’ ìŒì„ ì…ë ¥í•©ë‹ˆë‹¤.
- íŒŒë¼ë¯¸í„°ê°€ í•„ìš” ì—†ëŠ” ëª…ë ¹ì–´ëŠ” ë‹¤ìŒì„ ì‚¬ìš©í•´ ì˜ë¯¸ë¥¼ ëª…ì‹œí•©ë‹ˆë‹¤:
    - `{"note": "no parameters needed"}`
 
ì˜ˆì‹œ:
- B2:B10ì˜ í•©ê³„ë¥¼ B11ì— í‘œì‹œ: command_type="sum", target_range="B11", parameters={"range": "B2:B10"}
- A1 ì…€ì„ êµµê²Œ: command_type="bold", target_range="A1", parameters={"note": "no parameters needed"}
- C1:C5ë¥¼ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ: command_type="font_color", target_range="C1:C5", parameters={"color": "FF0000"}

ì‘ë‹µì€ í•­ìƒ ì¹œì ˆí•˜ê³  ëª…í™•í•œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

    def _create_user_prompt(
            self,
            summary: str,
            user_command: str,
            excel_context: str
    ) -> str:
        """ì‚¬ìš©ìì˜ ëª…ë ¹ê³¼ í˜„ì¬ ìƒí™©ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸"""
        return f"""ì´ì „ ëŒ€í™” ìš”ì•½:


í˜„ì¬ ì„¸ì…˜ ìš”ì•½:
{summary}

í˜„ì¬ ì—‘ì…€ íŒŒì¼ ìƒíƒœ:
{excel_context}

ì‚¬ìš©ì ëª…ë ¹:
{user_command}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ëª…ë ¹ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì—‘ì…€ ëª…ë ¹ì–´ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•˜ê³ ,
ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•œ í•œêµ­ì–´ ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""
